{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not `use_min`, the optimazation goal is to minimize the following function:\n",
    "$$\n",
    "\\text{Error}(d) = \\sum_{j=0}^{N-1} \\left( x_j - d \\cdot q_j \\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already know $x_j$ and $q_j$, when:\n",
    "$$\n",
    "d = \\frac{\\sum_{j=0}^{N-1} x_j \\cdot q_j}{\\sum_{j=0}^{N-1} q_j^2}\n",
    "$$\n",
    "makes $\\text{Error}$ smallest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `use_min`:\n",
    "$$\n",
    "E = \\sum_{i=0}^{n-1} \\left( \\text{scale} \\cdot l_i + \\text{min} - x_i \\right)^2\n",
    "$$\n",
    "Already know $x_j$ and $l_j$, when:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{scale} = \\frac{N\\sum_{i=0}^{N-1} l_ix_i - \\sum_{i=0}^{N-1}x_i\\sum_{i=0}^{N-1}l_i }{N\\sum_{i=0}^{N-1}l_i^2 - (\\sum_{i=0}^{N-1}l_i)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{min} = \\frac{\\sum_{i=0}^{N-1} x_i \\sum_{i=0}^{N-1} l_i^2- \\sum_{i=0}^{N-1}x_il_i\\sum_{i=0}^{N-1}l_i }{N\\sum_{i=0}^{N-1}l_i^2 - (\\sum_{i=0}^{N-1}l_i)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "makes $\\text{E}$ smallest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class quantizer:\n",
    "    def __init__(self, n_bits: int = 8, use_min: bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_bits (int): number of bits\n",
    "            bsz (int): block size\n",
    "        \"\"\"\n",
    "        self.n_bits = n_bits\n",
    "        self.q_range = 2**n_bits - 1\n",
    "        self.q_max = 2**(n_bits-1) - 1\n",
    "        self.q_min = -2**(n_bits-1)\n",
    "        self.use_min = use_min\n",
    "\n",
    "    def quantize(self, x: np.ndarray) -> tuple[np.ndarray, float, float]:\n",
    "        if not self.use_min:\n",
    "            x_abs = np.abs(x)\n",
    "            x_abs_max = np.max(x_abs)\n",
    "            scale = x_abs_max / self.q_min\n",
    "            q = np.clip(np.round(x / scale), self.q_min, self.q_max)\n",
    "            min = None\n",
    "        else:\n",
    "            scale = (np.max(x) - np.min(x)) / self.q_range\n",
    "            min = np.min(x)\n",
    "            q = np.clip(np.round((x - min) / scale), 0, self.q_range)\n",
    "        return q, scale, min\n",
    "\n",
    "    def dequantize(self, q: np.ndarray, scale: float, min: float) -> np.ndarray:\n",
    "        q = q.astype(np.float32)\n",
    "        if not self.use_min:\n",
    "            dq = q * scale # dequantize q\n",
    "        else:\n",
    "            dq = q * scale + min\n",
    "        return dq\n",
    "\n",
    "    def calc_mse(self, x: np.ndarray, dq: np.ndarray) -> float:\n",
    "        return np.mean((x - dq)**2)\n",
    "    \n",
    "    # recalculation of scale and min according to the formula above\n",
    "    def recalc_scale_and_min(self, x: np.ndarray, q: np.ndarray) -> tuple[float, float]:\n",
    "        assert x.shape == q.shape\n",
    "        if not self.use_min:\n",
    "            scale = (x * q).sum() / (q**2).sum()\n",
    "            min = None\n",
    "        else:\n",
    "            # get the element num of q\n",
    "            N = q.size\n",
    "            D = N * (q**2).sum() - q.sum()**2\n",
    "            scale = (N * (x * q).sum() - x.sum() * q.sum()) / D\n",
    "            min = (x.sum() * (q**2).sum() - q.sum() * (x * q).sum()) / D\n",
    "        return scale, min\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 10 * np.random.randn(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [ 5.63109251 -0.66333746 -3.7742885  -5.53918171 -8.02601077  3.97313181\n",
      "  0.47977315  3.40512398]\n",
      "q: [15.  8.  5.  3.  0. 13.  9. 13.]\n",
      "scale0: 0.910473552006432 min0: -8.026010772858172\n",
      "dq0: [ 5.631092   -0.7422223  -3.4736428  -5.29459    -8.0260105   3.8101454\n",
      "  0.16825104  3.8101454 ]\n",
      "mse0: 0.05551108470975463\n",
      "scale1: 0.9171847297558767 min1: -8.130986144472903\n",
      "dq1: [ 5.6267843 -0.7935085 -3.5450625 -5.379432  -8.130986   3.7924147\n",
      "  0.1236763  3.7924147]\n",
      "mse1: 0.05193813484932613\n"
     ]
    }
   ],
   "source": [
    "q1 = quantizer(n_bits=4, use_min=True)\n",
    "# q1 = quantizer(n_bits=4, use_min=False)\n",
    "q, scale0, min0 = q1.quantize(x)\n",
    "print(\"x:\", x)\n",
    "print(\"q:\", q)\n",
    "print(\"scale0:\", scale0, \"min0:\", min0)\n",
    "dq0 = q1.dequantize(q, scale0, min0)\n",
    "print (\"dq0:\", dq0)\n",
    "mse0 = q1.calc_mse(x, dq0)\n",
    "print(\"mse0:\", mse0)\n",
    "scale1, min1 = q1.recalc_scale_and_min(x, q)\n",
    "print(\"scale1:\", scale1, \"min1:\", min1)\n",
    "dq1 = q1.dequantize(q, scale1, min1)\n",
    "print (\"dq1:\", dq1)\n",
    "mse1 = q1.calc_mse(x, dq1)\n",
    "print(\"mse1:\", mse1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted quantization. the optimization function becomes:\n",
    "$$\n",
    "\\text{Error}(d) = \\sum_{j=0}^{N-1} w_j \\left( x_j - d \\cdot q_j \\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "d = \\frac{\\sum_{j=0}^{N-1} w_j \\cdot x_j \\cdot q_j}{\\sum_{j=0}^{N-1} w_j \\cdot q_j^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in `use_min` case, it becomes:\n",
    "$$\n",
    "E = \\sum_{i=0}^{n-1} w_i \\left( \\text{scale} \\cdot l_i + \\text{min} - x_i \\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{scale} = \\frac{\\sum_{i=0}^{N-1} w_il_ix_i \\sum_{i=0}^{N-1} w_i - \\sum_{i=0}^{N-1}w_ix_i\\sum_{i=0}^{N-1}w_il_i }{\\sum_{i=0}^{N-1} w_i \\sum_{i=0}^{N-1}w_il_i^2 - (\\sum_{i=0}^{N-1}w_il_i)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{min} = \\frac{\\sum_{i=0}^{N-1} w_ix_i \\sum_{i=0}^{N-1} w_il_i^2- \\sum_{i=0}^{N-1}w_ix_il_i\\sum_{i=0}^{N-1}w_il_i }{\\sum_{i=0}^{N-1}w_i \\sum_{i=0}^{N-1}w_il_i^2 - (\\sum_{i=0}^{N-1}w_il_i)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class quantizer_weighted:\n",
    "    \"\"\"\n",
    "    mse is calculated weighted, search the optimal scale and min  \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,  n_bits: int = 8, use_min: bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_bits (int): number of bits\n",
    "            bsz (int): block size\n",
    "        \"\"\"\n",
    "        self.n_bits = n_bits\n",
    "        self.q_range = 2**n_bits - 1\n",
    "        self.q_max = 2**(n_bits-1) - 1\n",
    "        self.q_min = -2**(n_bits-1)\n",
    "        self.use_min = use_min\n",
    "\n",
    "    def quantize(self, x: np.ndarray, offset: float) -> tuple[np.ndarray, float, float]:\n",
    "        if not self.use_min:\n",
    "            x_abs = np.abs(x)\n",
    "            x_abs_max = np.max(x_abs)\n",
    "            scale = (x_abs_max + offset) / self.q_min\n",
    "            q = np.clip(np.round(x / scale), self.q_min, self.q_max)\n",
    "            min = None\n",
    "        else:\n",
    "            scale = (np.max(x) - np.min(x) + offset) / self.q_range\n",
    "            min = np.min(x)\n",
    "            q = np.clip(np.round((x - min) / scale), 0, self.q_range)\n",
    "        return q, scale, min\n",
    "\n",
    "    def dequantize(self, q: np.ndarray, scale: float, min: float) -> np.ndarray:\n",
    "        q = q.astype(np.float32)\n",
    "        if not self.use_min:\n",
    "            dq = q * scale # dequantize q\n",
    "        else:\n",
    "            dq = q * scale + min\n",
    "        return dq\n",
    "\n",
    "    def calc_mse(self, x: np.ndarray, dq: np.ndarray, w: np.ndarray) -> float:\n",
    "        assert x.shape == dq.shape\n",
    "        assert w.shape == x.shape\n",
    "        return np.mean(w * (x - dq)**2)\n",
    "    \n",
    "    # recalculation of scale and min according to the formula above\n",
    "    def recalc_scale_and_min(self, x: np.ndarray, q: np.ndarray, w: np.ndarray) -> tuple[float, float]:\n",
    "        assert x.shape == q.shape\n",
    "        assert x.shape == w.shape\n",
    "        if not self.use_min:\n",
    "            scale = (w * x * q).sum() / (w * q**2).sum()\n",
    "            min = None\n",
    "        else:\n",
    "            # get the element num of q\n",
    "            D = w.sum() * (w * q**2).sum() - ((w * q).sum())**2\n",
    "            scale = (w.sum() * (w * x * q).sum() - (w * x).sum() * (w * q).sum()) / D\n",
    "            min = ((w * x).sum() * (w * q**2).sum() - (w * q).sum() * (w * x * q).sum()) / D\n",
    "        return scale, min\n",
    "    \n",
    "    def search_scale_and_min(self, x: np.ndarray, w: np.ndarray):\n",
    "        best_mse1 = np.inf\n",
    "        best_off = 0\n",
    "        for off in range(-10, 11):\n",
    "            q, scale0, min0 = self.quantize(x, off*0.1)\n",
    "            scale1, min1 = self.recalc_scale_and_min(x, q, w)\n",
    "            dq0 = self.dequantize(q, scale0, min0)\n",
    "            dq1 = self.dequantize(q, scale1, min1)\n",
    "            mse0 = self.calc_mse(x, dq0, w)\n",
    "            mse1 = self.calc_mse(x, dq1, w)\n",
    "            if mse1 < best_mse1:\n",
    "                best_mse1 = mse1\n",
    "                best_off = off\n",
    "            print(\"off:\", off, \"mse0:\", mse0,  \"mse1:\", mse1)\n",
    "            print(\"q:\", q)\n",
    "            print(\"scale0:\", scale0, \"min0:\", min0)\n",
    "            print(\"scale1:\", scale1, \"min1:\", min1)\n",
    "            print(\"dq0:\", dq0)\n",
    "            print(\"dq1:\", dq1)\n",
    "            print()\n",
    "        print(\"best_off:\", best_off)\n",
    "        print(\"best_mse1:\", best_mse1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = np.ones_like(x)\n",
    "w = 10 * np.random.rand(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "off: -10 mse0: 1.0040145708848196 mse1: 0.7030886704500996\n",
      "q: [15.  9.  5.  3.  0. 14. 10. 14.]\n",
      "scale0: 0.8438068853397653 min0: -8.026010772858172\n",
      "scale1: 0.8936402408642165 min1: -8.384840698270105\n",
      "dq0: [ 4.631092   -0.43174887 -3.8069763  -5.49459    -8.0260105   3.7872858\n",
      "  0.41205788  3.7872858 ]\n",
      "dq1: [ 5.019762   -0.34207916 -3.9166398  -5.7039204  -8.384841    4.1261225\n",
      "  0.55156136  4.1261225 ]\n",
      "\n",
      "off: -9 mse0: 0.848790786622413 mse1: 0.44622695493893827\n",
      "q: [15.  9.  5.  3.  0. 14. 10. 13.]\n",
      "scale0: 0.850473552006432 min0: -8.026010772858172\n",
      "scale1: 0.910816281149878 min1: -8.47379406539703\n",
      "dq0: [ 4.7310925  -0.37174892 -3.773643   -5.47459    -8.0260105   3.880619\n",
      "  0.47872448  3.0301456 ]\n",
      "dq1: [ 5.18845   -0.2764473 -3.9197125 -5.7413454 -8.473794   4.2776337\n",
      "  0.6343689  3.3668175]\n",
      "\n",
      "off: -8 mse0: 0.7123609377117937 mse1: 0.44622695493893827\n",
      "q: [15.  9.  5.  3.  0. 14. 10. 13.]\n",
      "scale0: 0.8571402186730986 min0: -8.026010772858172\n",
      "scale1: 0.910816281149878 min1: -8.47379406539703\n",
      "dq0: [ 4.831093   -0.3117485  -3.7403092  -5.45459    -8.0260105   3.9739532\n",
      "  0.54539204  3.1168127 ]\n",
      "dq1: [ 5.18845   -0.2764473 -3.9197125 -5.7413454 -8.473794   4.2776337\n",
      "  0.6343689  3.3668175]\n",
      "\n",
      "off: -7 mse0: 0.6224006546260493 mse1: 0.44622695493893827\n",
      "q: [15.  9.  5.  3.  0. 14. 10. 13.]\n",
      "scale0: 0.8638068853397655 min0: -8.026010772858172\n",
      "scale1: 0.910816281149878 min1: -8.47379406539703\n",
      "dq0: [ 4.931093   -0.25174856 -3.706976   -5.43459    -8.0260105   4.0672865\n",
      "  0.61205864  3.2034788 ]\n",
      "dq1: [ 5.18845   -0.2764473 -3.9197125 -5.7413454 -8.473794   4.2776337\n",
      "  0.6343689  3.3668175]\n",
      "\n",
      "off: -6 mse0: 0.5213139781470112 mse1: 0.3795549556740102\n",
      "q: [15.  8.  5.  3.  0. 14. 10. 13.]\n",
      "scale0: 0.8704735520064321 min0: -8.026010772858172\n",
      "scale1: 0.8949839287721524 min1: -8.122941377307088\n",
      "dq0: [ 5.0310926  -1.062222   -3.6736426  -5.41459    -8.0260105   4.1606197\n",
      "  0.67872524  3.2901459 ]\n",
      "dq1: [ 5.301818   -0.96306944 -3.6480212  -5.437989   -8.122941    4.4068346\n",
      "  0.8268986   3.5118504 ]\n",
      "\n",
      "off: -5 mse0: 0.4333805362225287 mse1: 0.3795549556740102\n",
      "q: [15.  8.  5.  3.  0. 14. 10. 13.]\n",
      "scale0: 0.8771402186730987 min0: -8.026010772858172\n",
      "scale1: 0.8949839287721524 min1: -8.122941377307088\n",
      "dq0: [ 5.131093   -1.0088887  -3.6403093  -5.39459    -8.0260105   4.253953\n",
      "  0.74539185  3.376812  ]\n",
      "dq1: [ 5.301818   -0.96306944 -3.6480212  -5.437989   -8.122941    4.4068346\n",
      "  0.8268986   3.5118504 ]\n",
      "\n",
      "off: -4 mse0: 0.3905420224981616 mse1: 0.3795549556740102\n",
      "q: [15.  8.  5.  3.  0. 14. 10. 13.]\n",
      "scale0: 0.8838068853397654 min0: -8.026010772858172\n",
      "scale1: 0.8949839287721524 min1: -8.122941377307088\n",
      "dq0: [ 5.2310925  -0.95555544 -3.606976   -5.37459    -8.0260105   4.347286\n",
      "  0.81205845  3.463479  ]\n",
      "dq1: [ 5.301818   -0.96306944 -3.6480212  -5.437989   -8.122941    4.4068346\n",
      "  0.8268986   3.5118504 ]\n",
      "\n",
      "off: -3 mse0: 0.3770912010591192 mse1: 0.33899066921589144\n",
      "q: [15.  8.  5.  3.  0. 13. 10. 13.]\n",
      "scale0: 0.890473552006432 min0: -8.026010772858172\n",
      "scale1: 0.9114184117662343 min1: -8.202617282534854\n",
      "dq0: [ 5.331093   -0.90222216 -3.5736427  -5.35459    -8.0260105   3.5501451\n",
      "  0.87872505  3.5501451 ]\n",
      "dq1: [ 5.4686584  -0.91127014 -3.6455255  -5.4683623  -8.202618    3.6458225\n",
      "  0.91156673  3.6458225 ]\n",
      "\n",
      "off: -2 mse0: 0.33141830523019955 mse1: 0.20716456936865685\n",
      "q: [15.  8.  5.  3.  0. 13.  9. 13.]\n",
      "scale0: 0.8971402186730988 min0: -8.026010772858172\n",
      "scale1: 0.9094308610266039 min1: -7.982873693690507\n",
      "dq0: [ 5.4310923  -0.8488889  -3.5403094  -5.33459    -8.0260105   3.6368122\n",
      "  0.04825115  3.6368122 ]\n",
      "dq1: [ 5.6585894  -0.707427   -3.4357195  -5.2545815  -7.982874    3.8397274\n",
      "  0.20200348  3.8397274 ]\n",
      "\n",
      "off: -1 mse0: 0.2504078869602773 mse1: 0.20716456936865685\n",
      "q: [15.  8.  5.  3.  0. 13.  9. 13.]\n",
      "scale0: 0.9038068853397654 min0: -8.026010772858172\n",
      "scale1: 0.9094308610266039 min1: -7.982873693690507\n",
      "dq0: [ 5.5310926  -0.7955556  -3.5069761  -5.31459    -8.0260105   3.7234783\n",
      "  0.10825157  3.7234783 ]\n",
      "dq1: [ 5.6585894  -0.707427   -3.4357195  -5.2545815  -7.982874    3.8397274\n",
      "  0.20200348  3.8397274 ]\n",
      "\n",
      "off: 0 mse0: 0.2119455481862777 mse1: 0.20716456936865685\n",
      "q: [15.  8.  5.  3.  0. 13.  9. 13.]\n",
      "scale0: 0.910473552006432 min0: -8.026010772858172\n",
      "scale1: 0.9094308610266039 min1: -7.982873693690507\n",
      "dq0: [ 5.631092   -0.7422223  -3.4736428  -5.29459    -8.0260105   3.8101454\n",
      "  0.16825104  3.8101454 ]\n",
      "dq1: [ 5.6585894  -0.707427   -3.4357195  -5.2545815  -7.982874    3.8397274\n",
      "  0.20200348  3.8397274 ]\n",
      "\n",
      "off: 1 mse0: 0.19096210799859303 mse1: 0.17367358972912017\n",
      "q: [15.  8.  5.  3.  0. 13.  9. 12.]\n",
      "scale0: 0.9171402186730987 min0: -8.026010772858172\n",
      "scale1: 0.9238409450693431 min1: -8.033214600278937\n",
      "dq0: [ 5.7310934  -0.68888855 -3.4403095  -5.2745895  -8.0260105   3.8968124\n",
      "  0.22825146  2.9796724 ]\n",
      "dq1: [ 5.8244     -0.64248705 -3.41401    -5.261692   -8.033215    3.976718\n",
      "  0.28135395  3.0528765 ]\n",
      "\n",
      "off: 2 mse0: 0.17387660991809928 mse1: 0.17367358972912017\n",
      "q: [15.  8.  5.  3.  0. 13.  9. 12.]\n",
      "scale0: 0.9238068853397653 min0: -8.026010772858172\n",
      "scale1: 0.9238409450693431 min1: -8.033214600278937\n",
      "dq0: [ 5.831093   -0.63555527 -3.4069757  -5.25459    -8.0260105   3.9834795\n",
      "  0.28825188  3.0596724 ]\n",
      "dq1: [ 5.8244     -0.64248705 -3.41401    -5.261692   -8.033215    3.976718\n",
      "  0.28135395  3.0528765 ]\n",
      "\n",
      "off: 3 mse0: 0.19842169349388666 mse1: 0.17367358972912017\n",
      "q: [15.  8.  5.  3.  0. 13.  9. 12.]\n",
      "scale0: 0.9304735520064321 min0: -8.026010772858172\n",
      "scale1: 0.9238409450693431 min1: -8.033214600278937\n",
      "dq0: [ 5.931093   -0.582222   -3.373643   -5.2345896  -8.0260105   4.0701456\n",
      "  0.34825134  3.1396723 ]\n",
      "dq1: [ 5.8244     -0.64248705 -3.41401    -5.261692   -8.033215    3.976718\n",
      "  0.28135395  3.0528765 ]\n",
      "\n",
      "off: 4 mse0: 0.2645965823195453 mse1: 0.17367358972912017\n",
      "q: [15.  8.  5.  3.  0. 13.  9. 12.]\n",
      "scale0: 0.9371402186730987 min0: -8.026010772858172\n",
      "scale1: 0.9238409450693431 min1: -8.033214600278937\n",
      "dq0: [ 6.0310926  -0.5288887  -3.3403091  -5.21459    -8.0260105   4.1568127\n",
      "  0.40825176  3.2196722 ]\n",
      "dq1: [ 5.8244     -0.64248705 -3.41401    -5.261692   -8.033215    3.976718\n",
      "  0.28135395  3.0528765 ]\n",
      "\n",
      "off: 5 mse0: 0.3259171305127399 mse1: 0.22598152261093718\n",
      "q: [14.  8.  5.  3.  0. 13.  9. 12.]\n",
      "scale0: 0.9438068853397653 min0: -8.026010772858172\n",
      "scale1: 0.9823507234300677 min1: -8.39196769613065\n",
      "dq0: [ 5.1872864  -0.47555542 -3.3069763  -5.1945896  -8.0260105   4.243479\n",
      "  0.46825123  3.2996721 ]\n",
      "dq1: [ 5.360942   -0.5331621  -3.480214   -5.444916   -8.391968    4.3785915\n",
      "  0.44918823  3.3962402 ]\n",
      "\n",
      "off: 6 mse0: 0.2949741139862314 mse1: 0.29170114867758995\n",
      "q: [14.  8.  4.  3.  0. 13.  9. 12.]\n",
      "scale0: 0.950473552006432 min0: -8.026010772858172\n",
      "scale1: 0.9553330174575119 min1: -8.051741626609104\n",
      "dq0: [ 5.2806187  -0.42222214 -4.2241163  -5.17459    -8.0260105   4.330146\n",
      "  0.52825165  3.379672  ]\n",
      "dq1: [ 5.322921   -0.40907764 -4.2304096  -5.1857424  -8.051742    4.367587\n",
      "  0.5462551   3.4122543 ]\n",
      "\n",
      "off: 7 mse0: 0.2996780506625857 mse1: 0.29170114867758995\n",
      "q: [14.  8.  4.  3.  0. 13.  9. 12.]\n",
      "scale0: 0.9571402186730986 min0: -8.026010772858172\n",
      "scale1: 0.9553330174575119 min1: -8.051741626609104\n",
      "dq0: [ 5.373953   -0.36888885 -4.1974497  -5.1545897  -8.0260105   4.416812\n",
      "  0.5882511   3.459672  ]\n",
      "dq1: [ 5.322921   -0.40907764 -4.2304096  -5.1857424  -8.051742    4.367587\n",
      "  0.5462551   3.4122543 ]\n",
      "\n",
      "off: 8 mse0: 0.30642928125718594 mse1: 0.29928066910627893\n",
      "q: [14.  8.  4.  3.  0. 12.  9. 12.]\n",
      "scale0: 0.9638068853397654 min0: -8.026010772858172\n",
      "scale1: 0.9732904339820229 min1: -8.128240834228707\n",
      "dq0: [ 5.467285   -0.31555557 -4.170783   -5.13459    -8.0260105   3.539672\n",
      "  0.64825153  3.539672  ]\n",
      "dq1: [ 5.4978256  -0.34191704 -4.235079   -5.2083693  -8.128241    3.5512447\n",
      "  0.6313734   3.5512447 ]\n",
      "\n",
      "off: 9 mse0: 0.32488415651405295 mse1: 0.29928066910627893\n",
      "q: [14.  8.  4.  3.  0. 12.  9. 12.]\n",
      "scale0: 0.970473552006432 min0: -8.026010772858172\n",
      "scale1: 0.9732904339820229 min1: -8.128240834228707\n",
      "dq0: [ 5.5606194 -0.2622223 -4.1441164 -5.1145897 -8.0260105  3.6196718\n",
      "  0.708251   3.6196718]\n",
      "dq1: [ 5.4978256  -0.34191704 -4.235079   -5.2083693  -8.128241    3.5512447\n",
      "  0.6313734   3.5512447 ]\n",
      "\n",
      "off: 10 mse0: 0.381515647826167 mse1: 0.29928066910627893\n",
      "q: [14.  8.  4.  3.  0. 12.  9. 12.]\n",
      "scale0: 0.9771402186730987 min0: -8.026010772858172\n",
      "scale1: 0.9732904339820229 min1: -8.128240834228707\n",
      "dq0: [ 5.6539526  -0.20888853 -4.1174498  -5.0945897  -8.0260105   3.6996727\n",
      "  0.7682514   3.6996727 ]\n",
      "dq1: [ 5.4978256  -0.34191704 -4.235079   -5.2083693  -8.128241    3.5512447\n",
      "  0.6313734   3.5512447 ]\n",
      "\n",
      "best_off: 1\n",
      "best_mse1: 0.17367358972912017\n",
      "x: [ 5.63109251 -0.66333746 -3.7742885  -5.53918171 -8.02601077  3.97313181\n",
      "  0.47977315  3.40512398]\n"
     ]
    }
   ],
   "source": [
    "# x = 10 * np.random.randn(8)\n",
    "qtr = quantizer_weighted(n_bits=4, use_min=True)\n",
    "# qtr = quantizer_weighted(n_bits=4, use_min=False)\n",
    "qtr.search_scale_and_min(x, w)\n",
    "print(\"x:\", x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
